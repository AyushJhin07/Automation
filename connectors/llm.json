{
  "id": "llm",
  "name": "LLM (Large Language Model)",
  "description": "Large Language Model integration for AI-powered text generation and processing",
  "category": "AI/ML",
  "icon": "brain",
  "color": "#8B5CF6",
  "version": "1.0.0",
  "authentication": {
    "type": "api_key",
    "config": {
      "apiKeyLocation": "header",
      "apiKeyName": "Authorization",
      "apiKeyPrefix": "Bearer"
    }
  },
  "baseUrl": "https://api.openai.com/v1",
  "actions": [
    {
      "id": "generate_text",
      "name": "Generate Text",
      "description": "Generate text using a language model",
      "parameters": {
        "type": "object",
        "properties": {
          "prompt": {
            "type": "string",
            "description": "Input prompt for text generation"
          },
          "model": {
            "type": "string",
            "enum": ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo", "claude-3-opus", "claude-3-sonnet"],
            "default": "gpt-3.5-turbo",
            "description": "Language model to use"
          },
          "max_tokens": {
            "type": "number",
            "minimum": 1,
            "maximum": 4096,
            "default": 1000,
            "description": "Maximum number of tokens to generate"
          },
          "temperature": {
            "type": "number",
            "minimum": 0,
            "maximum": 2,
            "default": 0.7,
            "description": "Sampling temperature for randomness"
          },
          "top_p": {
            "type": "number",
            "minimum": 0,
            "maximum": 1,
            "default": 1,
            "description": "Nucleus sampling parameter"
          },
          "frequency_penalty": {
            "type": "number",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "description": "Frequency penalty for token repetition"
          },
          "presence_penalty": {
            "type": "number",
            "minimum": -2,
            "maximum": 2,
            "default": 0,
            "description": "Presence penalty for new topics"
          },
          "stop_sequences": {
            "type": "array",
            "items": {"type": "string"},
            "description": "Stop sequences to end generation"
          },
          "system_message": {
            "type": "string",
            "description": "System message to set behavior"
          }
        },
        "required": ["prompt"],
        "additionalProperties": false
      }
    },
    {
      "id": "chat_completion",
      "name": "Chat Completion",
      "description": "Complete a chat conversation",
      "parameters": {
        "type": "object",
        "properties": {
          "messages": {
            "type": "array",
            "items": {
              "type": "object",
              "properties": {
                "role": {"type": "string", "enum": ["system", "user", "assistant"]},
                "content": {"type": "string"}
              },
              "required": ["role", "content"]
            },
            "description": "Conversation messages"
          },
          "model": {
            "type": "string",
            "enum": ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo", "claude-3-opus", "claude-3-sonnet"],
            "default": "gpt-3.5-turbo",
            "description": "Language model to use"
          },
          "max_tokens": {
            "type": "number",
            "minimum": 1,
            "maximum": 4096,
            "default": 1000,
            "description": "Maximum number of tokens to generate"
          },
          "temperature": {
            "type": "number",
            "minimum": 0,
            "maximum": 2,
            "default": 0.7,
            "description": "Sampling temperature"
          },
          "stream": {
            "type": "boolean",
            "default": false,
            "description": "Stream the response"
          }
        },
        "required": ["messages"],
        "additionalProperties": false
      }
    }
  ],
  "triggers": [
    {
      "id": "text_generated",
      "name": "Text Generated",
      "description": "Triggered when text generation is completed",
      "type": "webhook",
      "parameters": {
        "type": "object",
        "properties": {
          "model": {
            "type": "string",
            "description": "Filter by model used"
          }
        },
        "required": [],
        "additionalProperties": false
      },
      "outputSchema": {
        "type": "object",
        "properties": {
          "id": {"type": "string"},
          "model": {"type": "string"},
          "generated_text": {"type": "string"},
          "usage": {"type": "object"},
          "created": {"type": "number"}
        }
      }
    }
  ],
  "testConnection": {
    "method": "GET",
    "endpoint": "/models"
  }
}